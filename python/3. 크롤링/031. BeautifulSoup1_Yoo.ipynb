{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HTML parsing을 위한 모듈\n",
    "- parsing : html 문서내에서 원하는 값만 추출하는 것\n",
    "- BeautifulSoup의 메인 패키지인 bs패키지에서 BeautifulSoup import\n",
    "- https://www.crummy.com/software/BeautifulSoup/bs4/doc/   \n",
    "- 서버에서 가져온 html을 xml구조로 변환하여 읽으면 트리 형태로 스크래핑 가능 -> 파서(parser) 필요\n",
    "- 파서 : lxml(주로 이용되는 패키지),html.parser,lxml-xml, html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '''\n",
    "<html>\n",
    "  <head>\n",
    "    <title>BeautifulSoup test</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <div id='upper' class='test' custom='good'>\n",
    "      <h3 title='Good Content Title'>Contents Title</h3>\n",
    "      <p>Test contents</p>\n",
    "    </div>\n",
    "    <div id='lower' class='test' custom='nice'>\n",
    "      <p>Test Test Test 1</p>\n",
    "      <p>Test Test Test 2</p>\n",
    "      <p>Test Test Test 3</p>\n",
    "    </div>\n",
    "  </body>\n",
    "</html>'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. BeautifulSoup 모듈 기본 사용법\n",
    "### 1.1 객체생성\n",
    "- BeautifulSoup(파싱할 HTML문서, 파싱에 사용할 파서(구문분석기))\n",
    "- HTML 문서에 대한 파싱이 끝나면 트리구조 형식의 DOM객체 생성\n",
    "- 객체의 태그 접근 방법 : 태그명을 .연산자와 함께 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"test\" custom=\"good\" id=\"upper\">\n",
      "<h3 title=\"Good Content Title\">Contents Title</h3>\n",
      "<p>Test contents</p>\n",
      "</div>\n",
      "\n",
      "<div class=\"test\" custom=\"good\" id=\"upper\">\n",
      "<h3 title=\"Good Content Title\">Contents Title</h3>\n",
      "<p>Test contents</p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "print(soup.body.div)\n",
    "print()\n",
    "print(soup.div)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 태그의 정보 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "div\n",
      "{'id': 'upper', 'class': ['test'], 'custom': 'good'}\n",
      "upper\n",
      "\n",
      "Contents Title\n",
      "Test contents\n",
      "\n",
      "Test contents\n"
     ]
    }
   ],
   "source": [
    "print(soup.div.name)\n",
    "print(soup.div.attrs)\n",
    "print(soup.div['id'])\n",
    "print(soup.div.get_text())\n",
    "print(soup.p.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 태그로부터 다른 태그로 이동\n",
    "- bs.태그명.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body>\n",
       "<div class=\"test\" custom=\"good\" id=\"upper\">\n",
       "<h3 title=\"Good Content Title\">Contents Title</h3>\n",
       "<p>Test contents</p>\n",
       "</div>\n",
       "<div class=\"test\" custom=\"nice\" id=\"lower\">\n",
       "<p>Test Test Test 1</p>\n",
       "<p>Test Test Test 2</p>\n",
       "<p>Test Test Test 3</p>\n",
       "</div>\n",
       "</body>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.div.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bs.태그명.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', <h3 title=\"Good Content Title\">Contents Title</h3>, '\\n', <p>Test contents</p>, '\\n']\n"
     ]
    }
   ],
   "source": [
    "print(list(soup.div.children))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bs.태그명.next_sibling : 다음 형제태그로 이동\n",
    "- bs.태그명.previous_sibling : 앞 형제태그로 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"test\" custom=\"nice\" id=\"lower\">\n",
      "<p>Test Test Test 1</p>\n",
      "<p>Test Test Test 2</p>\n",
      "<p>Test Test Test 3</p>\n",
      "</div>\n",
      "\n",
      "<div class=\"test\" custom=\"good\" id=\"upper\">\n",
      "<h3 title=\"Good Content Title\">Contents Title</h3>\n",
      "<p>Test contents</p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "tag2 = soup.div.next_sibling.next_sibling\n",
    "print(tag2)\n",
    "print()\n",
    "print(tag2.previous_sibling.previous_sibling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. find()\n",
    " - 특정 html tag를 검색\n",
    " - 검색 조건을 명시하여 찾고자하는 tag를 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h3 title=\"Good Content Title\">Contents Title</h3>\n",
      "<h3 title=\"Good Content Title\">Contents Title</h3>\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('h3'))\n",
    "print(soup.h3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>Test contents</p>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"test\" custom=\"good\" id=\"upper\">\n",
       "<h3 title=\"Good Content Title\">Contents Title</h3>\n",
       "<p>Test contents</p>\n",
       "</div>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('div')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- div의 lower를 찾고 싶다면.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"test\" custom=\"nice\" id=\"lower\">\n",
       "<p>Test Test Test 1</p>\n",
       "<p>Test Test Test 2</p>\n",
       "<p>Test Test Test 3</p>\n",
       "</div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"div\", custom='nice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"test\" custom=\"nice\" id=\"lower\">\n",
       "<p>Test Test Test 1</p>\n",
       "<p>Test Test Test 2</p>\n",
       "<p>Test Test Test 3</p>\n",
       "</div>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('div', id='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- class는 키워드라서 사용할 수 없다. class_로 해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"test\" custom=\"good\" id=\"upper\">\n",
       "<h3 title=\"Good Content Title\">Contents Title</h3>\n",
       "<p>Test contents</p>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('div', class_='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"test\" custom=\"good\" id=\"upper\">\n",
       "<h3 title=\"Good Content Title\">Contents Title</h3>\n",
       "<p>Test contents</p>\n",
       "</div>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attrs = {\"id\":\"upper\",\"class\":\"test\"}\n",
    "soup.find(\"div\", attrs=attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"test\" custom=\"good\" id=\"upper\">\n",
       "<h3 title=\"Good Content Title\">Contents Title</h3>\n",
       "<p>Test contents</p>\n",
       "</div>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attrs = {\"id\":\"upper\",\"class\":\"test\"}\n",
    "soup.find(\"div\", attrs=attrs)\n",
    "soup.find(\"div\", attrs={\"id\":\"upper\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. find_all()\n",
    " - find가 조건에 만족하는 하나의 tag만 검색한다면, find_all은 조건에 맞는 모든 tag를 리스트로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>Test contents</p>,\n",
       " <p>Test Test Test 1</p>,\n",
       " <p>Test Test Test 2</p>,\n",
       " <p>Test Test Test 3</p>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"test\" custom=\"good\" id=\"upper\">\n",
       " <h3 title=\"Good Content Title\">Contents Title</h3>\n",
       " <p>Test contents</p>\n",
       " </div>,\n",
       " <div class=\"test\" custom=\"nice\" id=\"lower\">\n",
       " <p>Test Test Test 1</p>\n",
       " <p>Test Test Test 2</p>\n",
       " <p>Test Test Test 3</p>\n",
       " </div>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('div',class_='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. get_text()  ******************거의 사용하는거\n",
    " - tag안의 value를 추출\n",
    " - 우리가 얻고자 하는 대부분의 정보는 value에 존재\n",
    " - 부모tag의 경우, 모든 자식 tag의 value를 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h3 title=\"Good Content Title\">Contents Title</h3>\n",
      "Contents Title\n"
     ]
    }
   ],
   "source": [
    "tag = soup.find('h3')\n",
    "print(tag)\n",
    "print(tag.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Test contents</p>\n",
      "Test contents\n"
     ]
    }
   ],
   "source": [
    "tag = soup.find('p')\n",
    "print(tag)\n",
    "print(tag.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"test\" custom=\"nice\" id=\"lower\">\n",
      "<p>Test Test Test 1</p>\n",
      "<p>Test Test Test 2</p>\n",
      "<p>Test Test Test 3</p>\n",
      "</div>\n",
      "\n",
      "Test Test Test 1\n",
      "Test Test Test 2\n",
      "Test Test Test 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tag = soup.find('div', id=\"lower\")\n",
    "print(tag)\n",
    "print(tag.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. attribute 값 추출하기\n",
    " - 경우에 따라 추출하고자 하는 값이 attribute에도 존재함\n",
    " - 이 경우에는 검색한 tag에 attribute 이름을 [ ]연산을 통해 추출가능\n",
    " - 예) div.find('h3')['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h3 title=\"Good Content Title\">Contents Title</h3>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Good Content Title'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag = soup.find('h3')\n",
    "print(tag)\n",
    "tag['title']   # 링크 가져올때 많이 씀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. id, class 속성으로 tag 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**다음 뉴스 데이터 추출**\n",
    "- 뉴스기사에서 제목, 작성자, 작성일 추출\n",
    "- tag를 추출할때는 가장 그 tag를 쉽게 특정할 수 있는 속성을 사용\n",
    "- id의 경우 원칙적으로 한 html 문서 내에서 유일\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://news.v.daum.net/v/20210829114520406'\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "soup = BeautifulSoup(res.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. class 속성으로 tag 찾기\n",
    " - 타이틀\n",
    " - 작성자, 작성일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미군 등 철수시한 임박 카불공항..탈레반 \"넘겨받을 준비\"'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = soup.find('h3', class_='tit_view')\n",
    "title.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span class=\"txt_info\">성혜미</span>\n",
      "<span class=\"txt_info\">입력 <span class=\"num_date\">2021. 08. 29. 11:45</span></span>\n"
     ]
    }
   ],
   "source": [
    "# 방법1 : 전체 문서에서 찾는 법\n",
    "print(soup.find_all('span',class_=\"txt_info\")[0])\n",
    "print(soup.find_all('span',class_=\"txt_info\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "성혜미\n",
      "2021. 08. 29.\n"
     ]
    }
   ],
   "source": [
    "# 방법2 : 부모클래스를 찾고 info_view 내에서 다시 찾는다.\n",
    "# 범위를 줄여가면서 찾는 방법\n",
    "\n",
    "info = soup.find('span', class_='info_view')\n",
    "#print(info)\n",
    "\n",
    "print(info.find('span', class_='txt_info').get_text())\n",
    "print(info.find('span',class_='num_date').get_text()[:13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 id 속성으로 tag 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(자카르타=연합뉴스) 성혜미 특파원 = 미군 등 외국군과 조력자의 아프가니스탄 철수시한이 이틀 앞으로 다가온 29일 탈레반은 수도 카불공항 주변을 거의 봉쇄하고 넘겨받을 준비를 하고 있다.\n",
      "영국군을 태운 마지막 수송기가 카불공항에서 이륙하는 등 대다수 국가가 아프간 대피 작전을 속속 마무리했다.\n",
      "\n",
      "영국 국방부는 전날 \"영국군을 태운 마지막 수송기가 카불을 떠났다\"며 사진과 함께 트윗을 올렸다.\n",
      "독일, 이탈리아, 스위스, 스웨덴, 핀란드 등 유럽국가들은 27∼28일 대부분 대피 작전 종료를 선언했다.\n",
      "이들 국가는 아프간에 남은 자국민과 조력자에 대해 \"모두 데려오지 못해 유감\"이라며 대피 작전 종료 이후에도 육로를 통한 탈출 지원 등 노력을 계속하겠다는 입장이다.\n",
      "특히 에마뉘엘 마크롱 프랑스 대통령은 카불에 유엔이 통제하는 '안전지대'(safe zone)를 조성하자며, 30일 예정된 유엔안보리 긴급회의에 영국과 함께 이 방안을 제안할 계획이라고 밝혔다.\n",
      "마크롱 대통령은 \"카불에 안전지대를 만들면 인도주의적 활동을 지속할 수 있다. 안전지대는 유엔이 비상시에 움직일 수 있는 틀을 마련해 줄 것\"이라고 말했다.\n",
      "\n",
      "카불공항은 지난 26일 발생한 이슬람국가(IS)의 자살폭탄테러 사건 이후 현지인들의 접근이 거의 차단된 상황이다.\n",
      "이전에는 수송기 탑승 명단에 오른 현지인 조력자뿐만 아니라, 수많은 현지인이 공항 담벼락 주변에 장사진을 치고 \"우리도 태워달라\"며 실낱같은 희망을 품고 기다렸다.\n",
      "하지만, 26일 카불공항 외곽에서 대형 테러가 발생해 170명 이상이 숨지고, 1천300명 이상이 다치자 탈레반은 공항 경계를 강화한다며 장갑차 등을 동원해 주변 접근을 차단했다.\n",
      "공항 가는 길목에 검문소를 늘리고, 탈레반 대원들을 추가로 투입했다.\n",
      "\n",
      "더구나, 카불공항 추가 테러 경고가 나온 상태다.\n",
      "카불 주재 미 대사관은 이날 \"구체적이고 신뢰할만한 (테러) 위협이 있다\"면서 \"카불 공항 인근에 있는 모든 미국 시민은 즉시 공항을 떠나야 한다\"고 경보령을 내렸다.\n",
      "대사관은 특히 사우스(에어포트 서클) 게이트, 내무부 신청사, 공항 북서쪽에 있는 판지시르 주유소 근처 게이트에 테러 위협이 제기됐다고 구체적으로 적시했다.\n",
      "자비훌라 무자히드 탈레반 대변인은 \"우리 대원들이 공항 내부로 들어갔고, 미군이 떠나고 나면 평화롭게 공항 통제권을 넘겨받을 준비가 돼 있다\"고 전날 말했다.\n",
      "존 커비 미 국방부 대변인은 '공항 내부로 들어갔다'는 탈레반 대변인 주장을 부인했다.\n",
      "이달 15일 탈레반이 20년만에 아프간의 정권을 다시 잡은 뒤 미군과 국제동맹군이 카불공항 내부, 탈레반이 카불공항 외부 통제권을 가졌다.\n",
      "\n",
      "즉시 아프간을 떠날 수 있는 유일한 탈출구인 '카불공항'이 곧 막히게 되자 현지인들은 육로를 통해 국경 지역에 몰리고 있다.\n",
      "아프간은 이란, 파키스탄, 투르크메니스탄, 우즈베키스탄, 타지키스탄, 중국의 신장(新疆) 위구르 자치구와 국경을 접하고 있다.\n",
      "육로를 이용해 파키스탄, 이란 등으로 탈출하는 방법이 완전히 차단되지는 않았지만, 탈레반이 주요 길목을 통제하고 있고 무역상이나 여행허가증을 가진 이들이 아니면 국경 통과가 사실상 불가능하다.\n",
      "주변국들은 이미 아프간 난민이 넘치기에 추가 난민 유입에 난색을 보인다.\n",
      "파키스탄 당국은 최근 북부 토르캄과 남서부 차만 등 아프간과 연결되는 주요 검문소의 경계와 신원 확인 절차를 크게 강화했다.\n",
      "아프간과 900㎞ 길이의 국경을 접한 이란도 접경지역 경비를 강화하고, 시스탄-바-발루치스탄주는 난민이 국경을 넘지 못하도록 철조망을 설치했다.\n",
      "\n",
      "noanoa@yna.co.kr\n",
      "저작권자(c)연합뉴스. 무단전재-재배포금지\n"
     ]
    }
   ],
   "source": [
    "contents = soup.find('div', id = \"harmonyContainer\")\n",
    "#contents.find_all('p')\n",
    "for p in contents.find_all('p'):\n",
    "    print(p.get_text().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**연습문제1) 네이버 뉴스에서 제목, 기자, 날짜, 기사내용 크롤링 하기**\n",
    "- 참고 : 네이버 뉴스는 헤더정보 넣어서 요청해야함.\n",
    "- res = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제목 : 결국 법정싸움으로 간 남양유업 매각\n",
      "기자 : 정유미\n",
      "날짜 : 2021.08.30\n",
      "남양유업 매수인인 한앤컴퍼니(한앤코·사모펀드 운영사)는 지난 23일 서울중앙지법에 홍원식 남양유업 회장 등 매도인들을 상대로 거래종결 의무의 조속한 이행을 요구하는 소송을 제기했다고 30일 밝혔다.\n",
      "한앤컴퍼니는 “이번 소송은 매도인 측의 이유 없는 이행 지연, 무리한 요구, 계약해제 가능성 시사로 소송이 불가피하다는 판단에 따른 것”이라고 설명했다.\n",
      "이어 “인수·합병(M&A) 시장에서 생명과도 같은 계약과 약속을 경시하는 선례가 생길 것에 대한 우려가 크다”며 “남양유업의 잠재력에 대한 확신과 당사의 인수 의지에는 변함이 없어 매도인이 언제든 계약 이행을 결심하면 거래가 종결되고 소송도 자동으로 종료된다”고 말했다.\n",
      "한앤컴퍼니는 지난 5월27일 3107억원 규모의 남양유업 주식매매계약이 체결된 이후 공정거래위원회 승인을 거쳐 거래 종결일을 지난달 30일 오전 10시로 확정했다.\n",
      "이에 따라 홍 회장 측은 지난달 15일 이사회를 열어 회사 매각을 위한 임시주총을 지난달 30일 오전 9시에 열기로 했다. 임원 선임·사임 등기와 상호 증권계좌 확인 등 각종 제반 절차도 거래 종결일을 기준으로 준비됐다.\n",
      "한앤컴퍼니는 “거래종결일이 임박한 시기에 매도인 측에서 별도의 법무법인을 조용히 선임했다는 사실을 우연히 접하고 계획에 차질은 없는지 확인차 문의했다”며 “그제야 매도인은 하루전인 7월29일 오후 10시쯤 ‘거래종결일이 7월30일이라는 통지를 받아본 적이 없다’는 이해할 수 없는 주장의 공문을 보내왔다”고 주장했다. .\n",
      "홍 회장 측은 지난달 30일 준비가 더 필요하다는 이유로 주주총회를 오는 9월14일로 6주 연기하고 거래 종결 장소에 나타나지 않았다.\n",
      "한앤컴퍼니는 “매도인 측은 계속된 문의와 설득에도 2주 이상 묵묵부답으로 일관하다 무리한 사항들을 선결 조건으로 내세워 협상을 제안해왔다”며 “8월31일까지 협상이 타결되지 않을시 주식매매계약 해제 가능성까지 시사했다”고 주장했다.\n",
      "다만 한앤컴퍼니는 홍 회장 측의 무리한 요구가 무엇인지는 구체적으로 밝히지 않았다.\n",
      "한앤컴퍼니는 “매도인 측이 공언한 약속과 계약이 이행돼 당사뿐 아니라 남양유업의 임직원, 소액주주, 대리점, 낙농가 등 모든 이해관계자의 피해가 최소화되기를 바란다”고 말했다.\n",
      "홍 회장 측은 “거래 종결을 위한 협의 기한이 아직 남았고, 계약 이행을 위해 최선을 다해 협의를 제안하고 있는데 인수인 측이 소를 제기하고 보도자료까지 내면서 계약상 비밀유지 의무를 위반해 심히 유감”이라며 “그래도 우리는 최종 시한까지 협의를 계속할 예정”이라고 밝혔다.\n"
     ]
    }
   ],
   "source": [
    "url = 'http://biz.khan.co.kr/khan_art_view.html?artid=202108301450001&code=920100&nv=stand&utm_source=naver&utm_medium=newsstand&utm_campaign=sub_thumb3&utm_content=202108301450001&C='\n",
    "headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36\"}\n",
    "res = requests.get(url, headers=headers)\n",
    "res.raise_for_status()\n",
    "soup = BeautifulSoup(res.text, \"lxml\")\n",
    "\n",
    "#제목\n",
    "title = soup.find('h1', class_='headline')\n",
    "print('제목 :',title.get_text())\n",
    "\n",
    "#기자\n",
    "print('기자 :',soup.find('span',class_=\"name\").get_text()[:3])\n",
    "\n",
    "\n",
    "#날짜\n",
    "print('날짜 :',soup.find('div',class_=\"byline\").get_text()[6:16])\n",
    "\n",
    "#기사내용\n",
    "contents = soup.find('div', class_= \"art_cont\")\n",
    "for p in contents.find_all('p',class_='content_text'):\n",
    "    print(p.get_text().strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3>¹é½Å ¸Â°í ¹éÇ÷º´ ÆÇÁ¤ ÀÕµû¶ó¡¦ÀÌ¹ø¿£ ÅÂ±Çµµ °üÀå</h3>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다시\n",
    "\n",
    "url = 'http://news.kmib.co.kr/article/view.asp?arcid=0016216715&code=61121111&sid1=soc&cp=nv2'\n",
    "headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36\"}\n",
    "res = requests.get(url, headers=headers)\n",
    "res.raise_for_status()\n",
    "soup = BeautifulSoup(res.text, \"lxml\")\n",
    "\n",
    "#제목\n",
    "ti = soup.find('div', class_='nwsti_inner')\n",
    "title = ti.find('div', class_='nwsti')\n",
    "title.find('h3')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"코로나 지원금 얼마 받을까\" 네이버·카카오·토스로 확인하세요\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-73ddefeaa420>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'byline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_text'"
     ]
    }
   ],
   "source": [
    "url = 'http://biz.khan.co.kr/khan_art_view.html?artid=202108301215011&code=930201'\n",
    "headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36\"}\n",
    "res = requests.get(url, headers=headers)\n",
    "res.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(res.text, \"lxml\")\n",
    "\n",
    "# 타이틀 가져오기\n",
    "title = soup.find('h1', class_='headline')\n",
    "print(title.get_text())\n",
    "\n",
    "# 기자이름/날짜\n",
    "name = soup.find('a', class_='name')\n",
    "date = soup.find('div', class_='byline')\n",
    "print(name.get_text().strip(), '/', date.get_text().strip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 실전연습(네이버 웹툰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>네이버 만화 &gt; 요일별  웹툰 &gt; 전체웹툰</title>\n",
      "네이버 만화 > 요일별  웹툰 > 전체웹툰\n",
      "<a href=\"#menu\" onclick=\"document.getElementById('menu').tabIndex=-1;document.getElementById('menu').focus();return false;\"><span>메인 메뉴로 바로가기</span></a>\n",
      "\n",
      "{'href': '#menu', 'onclick': \"document.getElementById('menu').tabIndex=-1;document.getElementById('menu').focus();return false;\"}\n",
      "\n",
      "#menu\n"
     ]
    }
   ],
   "source": [
    "#html문서를 lxml파서를 통해서 beautiful 객체로 만들기. soup는 모든걸 가지고 있다.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://comic.naver.com/webtoon/weekday\"\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "soup = BeautifulSoup(res.text, \"lxml\")\n",
    "\n",
    "print(soup.title)\n",
    "print(soup.title.get_text())\n",
    "\n",
    "print(soup.a)\n",
    "print()\n",
    "print(soup.a.attrs)\n",
    "print()\n",
    "print(soup.a['href'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. 웹툰올리기 tag 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"Nbtn_upload\" href=\"/mypage/myActivity\" onclick=\"nclk_v2(event,'olk.upload');\">웹툰 올리기</a>\n",
      "<a class=\"Nbtn_upload\" href=\"/mypage/myActivity\" onclick=\"nclk_v2(event,'olk.upload');\">웹툰 올리기</a>\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('a', attrs={'class':'Nbtn_upload'}))\n",
    "print(soup.find(attrs={'class':'Nbtn_upload'}))    # 버튼속성이 하나일 것으로 예상되기 때문에 이 방법도 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. 인기 급상승 만화 tag 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인기 급상승 만화 정보 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li class=\"rank01\">\n",
      "<a href=\"/webtoon/detail?titleId=703846&amp;no=177\" onclick=\"nclk_v2(event,'rnk*p.cont','703846','1')\" title=\"여신강림-172화\">여신강림-172화</a>\n",
      "<span class=\"rankBox\">\n",
      "<img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/> 0\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t</span>\n",
      "</li>\n",
      "**************************************************\n",
      "<a href=\"/webtoon/detail?titleId=703846&amp;no=177\" onclick=\"nclk_v2(event,'rnk*p.cont','703846','1')\" title=\"여신강림-172화\">여신강림-172화</a>\n",
      "**************************************************\n",
      "여신강림-172화\n",
      "**************************************************\n",
      "https://comic.naver.com/webtoon/detail?titleId=703846&no=177\n"
     ]
    }
   ],
   "source": [
    "rank1 = soup.find(\"li\", attrs={'class':'rank01'})\n",
    "print(rank1)\n",
    "print('*'*50)\n",
    "\n",
    "print(rank1.a)\n",
    "print('*'*50)\n",
    "print(rank1.a.get_text())\n",
    "print('*'*50)\n",
    "print(\"https://comic.naver.com\"+rank1.a['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여신강림-172화\n",
      "한림체육관-66화\n",
      "사신소년-112화 ㅆ발\n",
      "한림체육관-66화\n",
      "[<li class=\"rank01\">\n",
      "<a href=\"/webtoon/detail?titleId=703846&amp;no=177\" onclick=\"nclk_v2(event,'rnk*p.cont','703846','1')\" title=\"여신강림-172화\">여신강림-172화</a>\n",
      "<span class=\"rankBox\">\n",
      "<img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/> 0\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t</span>\n",
      "</li>, <a href=\"/webtoon/detail?titleId=703846&amp;no=177\" onclick=\"nclk_v2(event,'rnk*p.cont','703846','1')\" title=\"여신강림-172화\">여신강림-172화</a>, <span class=\"rankBox\">\n",
      "<img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/> 0\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t</span>, <img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/>, <li class=\"rank02\">\n",
      "<a href=\"/webtoon/detail?titleId=743139&amp;no=66\" onclick=\"nclk_v2(event,'rnk*p.cont','743139','2')\" title=\"한림체육관-66화\">한림체육관-66화</a>\n",
      "<span class=\"rankBox\">\n",
      "<img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/> 0\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t</span>\n",
      "</li>, <a href=\"/webtoon/detail?titleId=743139&amp;no=66\" onclick=\"nclk_v2(event,'rnk*p.cont','743139','2')\" title=\"한림체육관-66화\">한림체육관-66화</a>, <span class=\"rankBox\">\n",
      "<img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/> 0\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t</span>, <img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/>, <li class=\"rank03\">\n",
      "<a href=\"/webtoon/detail?titleId=730656&amp;no=112\" onclick=\"nclk_v2(event,'rnk*p.cont','730656','3')\" title=\"사신소년-112화 ㅆ발\">사신소년-112화 ㅆ발</a>\n",
      "<span class=\"rankBox\">\n",
      "<img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/> 0\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t</span>\n",
      "</li>, <a href=\"/webtoon/detail?titleId=730656&amp;no=112\" onclick=\"nclk_v2(event,'rnk*p.cont','730656','3')\" title=\"사신소년-112화 ㅆ발\">사신소년-112화 ㅆ발</a>, <span class=\"rankBox\">\n",
      "<img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/> 0\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t</span>, <img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/>, <li class=\"rank04\">\n",
      "<a href=\"/webtoon/detail?titleId=738174&amp;no=80\" onclick=\"nclk_v2(event,'rnk*p.cont','738174','4')\" title=\"중증외상센터 : 골든 아워-2부 15화 : 알릴 건 알려야지\">중증외상센터 : 골든 아워-2부 15화 : 알릴 건 알려야지</a>\n",
      "<span class=\"rankBox\">\n",
      "<img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/> 0\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t</span>\n",
      "</li>, <a href=\"/webtoon/detail?titleId=738174&amp;no=80\" onclick=\"nclk_v2(event,'rnk*p.cont','738174','4')\" title=\"중증외상센터 : 골든 아워-2부 15화 : 알릴 건 알려야지\">중증외상센터 : 골든 아워-2부 15화 : 알릴 건 알려야지</a>, <span class=\"rankBox\">\n",
      "<img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/> 0\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t</span>, <img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/>, <li class=\"rank05\">\n",
      "<a href=\"/webtoon/detail?titleId=702608&amp;no=197\" onclick=\"nclk_v2(event,'rnk*p.cont','702608','5')\" title=\"랜덤채팅의 그녀!-197. 내로남불\">랜덤채팅의 그녀!-197. 내로남불</a>\n",
      "<span class=\"rankBox\">\n",
      "<img alt=\"순위상승\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_up.gif\" title=\"순위상승\" width=\"7\"/>1\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t</span>\n",
      "</li>, <a href=\"/webtoon/detail?titleId=702608&amp;no=197\" onclick=\"nclk_v2(event,'rnk*p.cont','702608','5')\" title=\"랜덤채팅의 그녀!-197. 내로남불\">랜덤채팅의 그녀!-197. 내로남불</a>, <span class=\"rankBox\">\n",
      "<img alt=\"순위상승\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_up.gif\" title=\"순위상승\" width=\"7\"/>1\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t</span>, <img alt=\"순위상승\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_up.gif\" title=\"순위상승\" width=\"7\"/>, <li class=\"rank06\">\n",
      "<a href=\"/webtoon/detail?titleId=738487&amp;no=88\" onclick=\"nclk_v2(event,'rnk*p.cont','738487','6')\" title=\"하루만 네가 되고 싶어-88. 삼자대면(2)\">하루만 네가 되고 싶어-88. 삼자대면(2)</a>\n",
      "<span class=\"rankBox\">\n",
      "<img alt=\"순위하락\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_down.gif\" title=\"순위하락\" width=\"7\"/>1\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t</span>\n",
      "</li>, <a href=\"/webtoon/detail?titleId=738487&amp;no=88\" onclick=\"nclk_v2(event,'rnk*p.cont','738487','6')\" title=\"하루만 네가 되고 싶어-88. 삼자대면(2)\">하루만 네가 되고 싶어-88. 삼자대면(2)</a>, <span class=\"rankBox\">\n",
      "<img alt=\"순위하락\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_down.gif\" title=\"순위하락\" width=\"7\"/>1\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t</span>, <img alt=\"순위하락\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_down.gif\" title=\"순위하락\" width=\"7\"/>, <li class=\"rank07\">\n",
      "<a href=\"/webtoon/detail?titleId=753856&amp;no=52\" onclick=\"nclk_v2(event,'rnk*p.cont','753856','7')\" title=\"달콤살벌한 부부-52화\">달콤살벌한 부부-52화</a>\n",
      "<span class=\"rankBox\">\n",
      "<img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/> 0\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t</span>\n",
      "</li>, <a href=\"/webtoon/detail?titleId=753856&amp;no=52\" onclick=\"nclk_v2(event,'rnk*p.cont','753856','7')\" title=\"달콤살벌한 부부-52화\">달콤살벌한 부부-52화</a>, <span class=\"rankBox\">\n",
      "<img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/> 0\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t</span>, <img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/>, <li class=\"rank08\">\n",
      "<a href=\"/webtoon/detail?titleId=759925&amp;no=28\" onclick=\"nclk_v2(event,'rnk*p.cont','759925','8')\" title=\"엽총소년-27화\">엽총소년-27화</a>\n",
      "<span class=\"rankBox\">\n",
      "<img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/> 0\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t</span>\n",
      "</li>, <a href=\"/webtoon/detail?titleId=759925&amp;no=28\" onclick=\"nclk_v2(event,'rnk*p.cont','759925','8')\" title=\"엽총소년-27화\">엽총소년-27화</a>, <span class=\"rankBox\">\n",
      "<img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/> 0\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t</span>, <img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/>, <li class=\"rank09\">\n",
      "<a href=\"/webtoon/detail?titleId=773459&amp;no=13\" onclick=\"nclk_v2(event,'rnk*p.cont','773459','9')\" title=\"용사가 돌아왔다-13화 용사들(1)\">용사가 돌아왔다-13화 용사들(1)</a>\n",
      "<span class=\"rankBox\">\n",
      "<img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/> 0\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t</span>\n",
      "</li>, <a href=\"/webtoon/detail?titleId=773459&amp;no=13\" onclick=\"nclk_v2(event,'rnk*p.cont','773459','9')\" title=\"용사가 돌아왔다-13화 용사들(1)\">용사가 돌아왔다-13화 용사들(1)</a>, <span class=\"rankBox\">\n",
      "<img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/> 0\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t</span>, <img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/>, <li class=\"rank10\">\n",
      "<a href=\"/webtoon/detail?titleId=683496&amp;no=233\" onclick=\"nclk_v2(event,'rnk*p.cont','683496','10')\" title=\"신도림-시즌2 93. 그릇\">신도림-시즌2 93. 그릇</a>\n",
      "<span class=\"rankBox\">\n",
      "<img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/> 0\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t</span>\n",
      "</li>, <a href=\"/webtoon/detail?titleId=683496&amp;no=233\" onclick=\"nclk_v2(event,'rnk*p.cont','683496','10')\" title=\"신도림-시즌2 93. 그릇\">신도림-시즌2 93. 그릇</a>, <span class=\"rankBox\">\n",
      "<img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/> 0\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t</span>, <img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/>]\n"
     ]
    }
   ],
   "source": [
    "rank1 = soup.find(\"li\", attrs={'class':'rank01'})\n",
    "print(rank1.a.get_text())\n",
    "\n",
    "rank2 = rank1.next_sibling.next_sibling\n",
    "print(rank2.a.get_text())\n",
    "\n",
    "rank3 = rank2.next_sibling.next_sibling\n",
    "print(rank3.a.get_text())\n",
    "\n",
    "rank2 = rank3.previous_sibling.previous_sibling\n",
    "print(rank2.a.get_text())\n",
    "\n",
    "# 부모태그\n",
    "print(rank1.parent())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find_next_sibling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한림체육관-66화\n",
      "사신소년-112화 ㅆ발\n"
     ]
    }
   ],
   "source": [
    "rank2 = rank1.find_next_sibling('li')\n",
    "print(rank2.a.get_text())\n",
    "\n",
    "rank3 = rank2.find_next_sibling('li')\n",
    "print(rank3.a.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find_next_siblings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여신강림-172화\n",
      "한림체육관-66화\n",
      "사신소년-112화 ㅆ발\n",
      "중증외상센터 : 골든 아워-2부 15화 : 알릴 건 알려야지\n",
      "랜덤채팅의 그녀!-197. 내로남불\n",
      "하루만 네가 되고 싶어-88. 삼자대면(2)\n",
      "달콤살벌한 부부-52화\n",
      "엽총소년-27화\n",
      "용사가 돌아왔다-13화 용사들(1)\n",
      "신도림-시즌2 93. 그릇\n"
     ]
    }
   ],
   "source": [
    "rank1 = soup.find(\"li\", attrs={'class':'rank01'})\n",
    "print(rank1.a.get_text())\n",
    "\n",
    "ranks = rank1.find_next_siblings('li')\n",
    "\n",
    "for rank in ranks:\n",
    "    print(rank.a.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#참고만_ 각 사이트별로 맞는 방법 택해서 사용\n",
    "ranks = soup.find(\"li\", attrs={'class':'asideBoxRank', 'id':'realTimeRankFavorite'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<a \n",
    "onclick=\"nclk_v2(event,'rnk*p.cont','703846','1')\" \n",
    "href=\"/webtoon/detail?titleId=703846&amp;no=177\" \n",
    "title=\"여신강림-172화\">여신강림-172화\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"/webtoon/detail?titleId=703846&amp;no=177\" onclick=\"nclk_v2(event,'rnk*p.cont','703846','1')\" title=\"여신강림-172화\">여신강림-172화</a>\n"
     ]
    }
   ],
   "source": [
    "webtoon = soup.find('a', text='여신강림-172화')\n",
    "print(webtoon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3. 네이버 웹툰 전체 목록 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "참교육\n",
      "신의 탑\n",
      "뷰티풀 군바리\n",
      "윈드브레이커\n",
      "팔이피플\n",
      "소녀의 세계\n",
      "장씨세가 호위무사\n",
      "백수세끼\n",
      "파이게임\n",
      "앵무살수\n",
      "만렙돌파\n",
      "삼매경\n",
      "잔불의 기사\n",
      "요리GO\n",
      "더블클릭\n",
      "약초마을 연쇄살초사건\n",
      "유일무이 로맨스\n",
      "칼가는 소녀\n",
      "바퀴\n",
      "히어로메이커\n",
      "결혼생활 그림일기\n",
      "물어보는 사이\n",
      "꼬리잡기\n",
      "영앤리치가 아니야!\n",
      "오늘의 순정망화\n",
      "ㅋㄷㅋㄷ만화\n",
      "리턴 투 플레이어\n",
      "평범한 8반\n",
      "아, 쫌 참으세요 영주님!\n",
      "아는 여자애\n",
      "수영만화일기\n",
      "황제와의 하룻밤\n",
      "장난감\n",
      "홍천기\n",
      "꿈의 기업\n",
      "순정말고 순종\n",
      "똑 닮은 딸\n",
      "최후의 금빛아이\n",
      "하루의 하루\n",
      "와이키키 뱀파이어\n",
      "야생천사 보호구역\n",
      "모스크바의 여명\n",
      "착한건 돈이된다\n",
      "사랑의 헌옷수거함\n",
      "선배, 그 립스틱 바르지 마요\n",
      "왕따협상\n",
      "이중첩자\n",
      "원하는 건 너 하나\n",
      "또다시, 계약 부부\n",
      "백호랑\n",
      "라서드\n",
      "마지막 지수\n",
      "사막에 핀 달\n",
      "드로잉 레시피\n",
      "중독연구소\n",
      "살아간다\n",
      "이탄국의 자청비\n",
      "모락모락 왕세자님\n",
      "그림자 신부\n",
      "바로 보지 않는\n",
      "개밥 먹는 남자\n",
      "헬로맨스\n",
      "보살님이 캐리해!\n",
      "오로지 오로라\n",
      "트리거\n",
      "기사님을 지켜줘\n",
      "여신강림\n",
      "용사가 돌아왔다\n",
      "덴큐\n",
      "한림체육관\n",
      "엽총소년\n",
      "하루만 네가 되고 싶어\n",
      "사신소년\n",
      "중증외상센터 : 골든 아워\n",
      "랜덤채팅의 그녀!\n",
      "신도림\n",
      "니나의 마법서랍\n",
      "헬58\n",
      "달콤살벌한 부부\n",
      "호랑이 들어와요\n",
      "천마는 평범하게 살 수 없다\n",
      "집이 없어\n",
      "오피스 누나 이야기\n",
      "원주민 공포만화\n",
      "몬스터\n",
      "블랙 위도우\n",
      "윌유메리미\n",
      "삼국지톡\n",
      "아이레\n",
      "위아더좀비\n",
      "하우스키퍼\n",
      "빌런투킬\n",
      "이상형은 아닙니다\n",
      "견우와 선녀\n",
      "오늘의 순정망화\n",
      "플레이, 플리\n",
      "용왕님의 셰프가 되었습니다\n",
      "기계증식증\n",
      "교환학생\n",
      "아이즈\n",
      "3cm 헌터\n",
      "제로게임\n",
      "정년이\n",
      "성인초딩\n",
      "올가미\n",
      "빅맨\n",
      "은주의 방 2~3부\n",
      "악인\n",
      "나타나주세요!\n",
      "연우의 순정\n",
      "나는 어디에나 있다\n",
      "열녀박씨 계약결혼뎐\n",
      "다꾸남\n",
      "숲속의 담\n",
      "나의 플랏메이트\n",
      "오파츠\n",
      "태시트\n",
      "조선홍보대행사 조대박\n",
      "그녀석 정복기\n",
      "안식의 밤\n",
      "대신 심부름을 해다오\n",
      "자판귀\n",
      "급식러너\n",
      "연애는 전쟁!\n",
      "완벽한 가족\n",
      "언메이크\n",
      "고등매직\n",
      "프린스 메이커\n",
      "지원이들\n",
      "풋내기들\n",
      "NG불가\n",
      "하나in세인\n",
      "피로만땅\n",
      "인문학적 감수성\n",
      "찐:종합게임동아리\n",
      "헬퍼 2 : 킬베로스\n",
      "전지적 독자 시점\n",
      "조조코믹스\n",
      "무서운게 딱좋아!\n",
      "모죠의 일지\n",
      "캐슬\n",
      "튜토리얼 탑의 고인물\n",
      "화산귀환\n",
      "급식아빠\n",
      "여주실격!\n",
      "남주의 첫날밤을 가져버렸다\n",
      "노곤하개\n",
      "세상은 돈과 권력\n",
      "66666년 만에 환생한 흑마법사\n",
      "일렉시드\n",
      "블랙홀과 3만원\n",
      "연놈\n",
      "닥터앤닥터 육아일기\n",
      "나쁜사람\n",
      "고삼무쌍\n",
      "마른 가지에 바람처럼\n",
      "엔딩 후 서브남을 주웠다\n",
      "빌드업\n",
      "원수를 사랑하라\n",
      "괴물공작의 딸\n",
      "관종교장\n",
      "밤낚시\n",
      "하렘의 남자들\n",
      "판타지 여동생!\n",
      "귀곡의 문\n",
      "사상최강\n",
      "언덕 위의 제임스\n",
      "방탈출\n",
      "아도나이\n",
      "마녀와 용의 신혼일기\n",
      "오징어도 사랑이 되나요?\n",
      "새벽 두 시의 신데렐라\n",
      "얼굴천재\n",
      "로어 올림푸스\n",
      "화가 살리에르\n",
      "럭키언럭키\n",
      "칼부림\n",
      "반귀\n",
      "범이올시다!\n",
      "속보입니다\n",
      "수요웹툰의 나강림\n",
      "반짝반짝 작은 눈\n",
      "사랑과 평강의 온달!\n",
      "무용과 남학생\n",
      "여우담:스윗싱가포르\n",
      "뱀은 꽃을 먹는가\n",
      "웰컴 온보드\n",
      "스캔들\n",
      "해귀\n",
      "기억흔적\n",
      "신선비\n",
      "천도\n",
      "저승사자 출입금지\n",
      "구주\n",
      "수상한 비밀상담부\n",
      "내 룸메이트는 마네킹\n",
      "나의 계절\n",
      "시효완성\n",
      "더 복서\n",
      "연애혁명\n",
      "기기괴괴\n",
      "나노마신\n",
      "이두나!\n",
      "묵시의 인플루언서\n",
      "화이트 블러드\n",
      "포식동물\n",
      "노답소녀\n",
      "정글쥬스\n",
      "겟백\n",
      "오빠세끼\n",
      "무사만리행\n",
      "하드캐리\n",
      "마왕까지 한 걸음\n",
      "던전 씹어먹는 아티팩트\n",
      "트롤트랩\n",
      "신비\n",
      "흑막 여주가 날 새엄마로 만들려고 해\n",
      "쿠베라\n",
      "최강전설 강해효\n",
      "별을 삼킨 너에게\n",
      "아빠같은 남자\n",
      "뜨거운 양철지붕 위의 고양이\n",
      "시에라\n",
      "선의의 경쟁\n",
      "오늘의 순정망화\n",
      "어느날 네가 떠올라!\n",
      "완벽한 결혼의 정석\n",
      "폭탄주먹 변대장\n",
      "마법사랑해\n",
      "만물의 영장\n",
      "안개무덤\n",
      "네가 죽기를 바랄 때가 있었다\n",
      "불편한 관계\n",
      "수영만화일기\n",
      "꽃만 키우는데 너무강함\n",
      "길티액스\n",
      "시월드 판타지\n",
      "마계인섬\n",
      "롤랑롤랑\n",
      "로그아웃\n",
      "THE 런웨이\n",
      "그 개, 만두\n",
      "성스러운 아이돌\n",
      "달의 요람\n",
      "그 황제가 시곗바늘을 되돌린 사연\n",
      "루커피쳐\n",
      "겟라이프\n",
      "야만의 시대\n",
      "어차피 남편은!\n",
      "집사레인저\n",
      "소년의 기록\n",
      "유리와 유리와 유리\n",
      "돌아온 여기사\n",
      "온새미로\n",
      "혼모노트\n",
      "온실 속 화초\n",
      "평범한 낙원\n",
      "카루나\n",
      "밤하늘에 구름운\n",
      "멸망X초이스\n",
      "헬프미\n",
      "보물과 괴물의 도시\n",
      "모어 라이프\n",
      "바른탕진 프로젝트\n",
      "외모지상주의\n",
      "나 혼자 만렙 뉴비\n",
      "유미의 세포들 외전 : 프로 직장인\n",
      "갓 오브 하이스쿨\n",
      "데드퀸\n",
      "1초\n",
      "죽지 않으려면\n",
      "개를 낳았다\n",
      "광마회귀\n",
      "서울역 드루이드\n",
      "식인귀\n",
      "말년용사\n",
      "세기말 풋사과 보습학원\n",
      "더 게이머\n",
      "여성전용헬스장 진달래짐\n",
      "블랙 위도우\n",
      "구남친이 내게 반했다\n",
      "상남자\n",
      "걸어서 30분\n",
      "플레이어\n",
      "삼국지톡\n",
      "그들이 사귀는 세상\n",
      "히어로 킬러\n",
      "환상의 용\n",
      "A.I. 닥터\n",
      "빨간맛 로맨스\n",
      "가슴털 로망스\n",
      "여우놀이\n",
      "역대급 영지 설계사\n",
      "감자마을\n",
      "그 기사가 레이디로 사는 법\n",
      "네버엔딩달링\n",
      "미친 후작을 길들이고 말았다\n",
      "엽사:요괴사냥꾼\n",
      "버그: 스티그마\n",
      "쌈빡\n",
      "피와 나비\n",
      "로판 빙의 만화\n",
      "후덜덜덜 남극전자\n",
      "인피니티\n",
      "다름이 아니라\n",
      "닥터 프로스트 시즌 3~4\n",
      "주님, 악마가 되게 해주세요!\n",
      "사람의 조각\n",
      "악몽일기\n",
      "너의 미소가 함정\n",
      "몽홀\n",
      "도무지 그애는\n",
      "거래\n",
      "태권보이\n",
      "방과후 선녀\n",
      "킬러방 : 퍼스트 킬\n",
      "아찔한 전남편\n",
      "트럼프\n",
      "빨리감기\n",
      "썸내일\n",
      "팬시X팬시\n",
      "백년게임\n",
      "꽃 피우는 남자\n",
      "나쁜 쪽으로\n",
      "구주의 시간\n",
      "찬란하지 않아도 괜찮아, 새벽\n",
      "진짜 정말 맹세코 좋아해\n",
      "행운을 빌어요, 용사님!\n",
      "합법해적 파르페\n",
      "강림전기 개정기\n",
      "매지컬 메디컬\n",
      "도깨비 고개\n",
      "조조코믹스\n",
      "호랑이형님\n",
      "프리드로우\n",
      "스퍼맨 : 전하지 못한 이야기\n",
      "취사병 전설이 되다\n",
      "모죠의 일지\n",
      "광장\n",
      "망나니 소교주로 환생했다\n",
      "최면학교\n",
      "니나의 마법서랍\n",
      "노곤하개\n",
      "욕망일기\n",
      "힙한남자\n",
      "스터디그룹\n",
      "나이트런\n",
      "윌유메리미\n",
      "나를 바꿔줘\n",
      "은둔코인\n",
      "반드시 해피엔딩\n",
      "어글리후드\n",
      "탑코너\n",
      "좀비 파이트\n",
      "피라미드 게임\n",
      "청춘 블라썸\n",
      "지구식 구원자 전형\n",
      "지옥급식\n",
      "태백 : 튜토리얼 맨\n",
      "나태 공자, 노력 천재 되다\n",
      "메트로헌터\n",
      "아홉수 우리들\n",
      "감 비서가 고장났다\n",
      "공유몽\n",
      "왕년엔 용사님\n",
      "웰캄투실버라이프\n",
      "먹이\n",
      "단편.zip\n",
      "남편을 만렙으로 키우려 합니다\n",
      "남자주인공의 여자사람친구입니다\n",
      "군주\n",
      "왕세자 입학도\n",
      "내게 필요한 NO맨스\n",
      "함부로 대해줘\n",
      "중매쟁이 아가 황녀님\n",
      "저무는 해, 시린 눈\n",
      "같은 학교 친구\n",
      "동네몬스터\n",
      "율리\n",
      "팔려 온 신부\n",
      "압락사스\n",
      "키스 식스 센스\n",
      "나를 길들여 봐, 차비서\n",
      "오늘부터 천생연분\n",
      "모두 너였다\n",
      "더 나우\n",
      "좋은데 어떡해\n",
      "주욱 같은 하루\n",
      "도사 가온\n",
      "안녕, 이바다씨\n",
      "아가사\n",
      "후아유!\n",
      "2-3승강장\n",
      "아침을 지나 밤으로\n",
      "인간졸업\n",
      "손 잡아 볼래?\n",
      "먹지마세요\n",
      "광해의 연인\n",
      "싸움독학\n",
      "수희0(tngmlek0)\n",
      "무서운게 딱좋아!\n",
      "이번 생도 잘 부탁해\n",
      "열렙전사\n",
      "약한영웅\n",
      "입학용병\n",
      "투신전생기\n",
      "어느날 갑자기 서울은\n",
      "닥터앤닥터 육아일기\n",
      "곱게 키웠더니, 짐승\n",
      "소녀재판\n",
      "경자 전성시대\n",
      "천하제일인\n",
      "오로지 너를 이기고 싶어\n",
      "테러대부활\n",
      "나만 보여!\n",
      "살아남은 로맨스\n",
      "내일\n",
      "마법스크롤 상인 지오\n",
      "사실 마법이었던 거임\n",
      "천치전능\n",
      "별이삼샵\n",
      "판사 이한영\n",
      "구름이 피워낸 꽃\n",
      "벚꽃이 흩날릴 무렵\n",
      "합격시켜주세용\n",
      "AI가 세상을 지배한다면\n",
      "로어 올림푸스\n",
      "예쁜 사나이\n",
      "강남도깨비\n",
      "취향 소개소\n",
      "혀로 만난 사이\n",
      "학교정벌\n",
      "동생친구\n",
      "평행도시\n",
      "생존로그\n",
      "아르세니아의 마법사\n",
      "거래하실래요?\n",
      "불순물\n",
      "몸이 바뀌는 사정\n",
      "전설의 화석\n",
      "결혼까지 망상했어!\n",
      "잉여특공대\n",
      "다시 또 봄\n",
      "짝사랑의 유서\n",
      "데빌샷\n",
      "사람은 고쳐 쓰는 게 아니야!\n",
      "황제에게 하트를 심어주세요\n",
      "패션쇼\n",
      "굿 리스너\n",
      "조선여우스캔들\n",
      "가짜인간\n",
      "소녀 해미\n",
      "독신마법사 기숙아파트\n",
      "라커, 오프너\n",
      "위험한 신입사원\n",
      "오늘 밤만 재워줘\n",
      "호수의 인어\n",
      "제타\n",
      "데이즈\n",
      "푸른불꽃\n",
      "샤인 스타\n",
      "호시탐탐\n"
     ]
    }
   ],
   "source": [
    "# 네이버 웹툰 전체 목록 가져오기\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url =\"https://comic.naver.com/webtoon/weekday\"\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "soup = BeautifulSoup(res.text, \"lxml\")\n",
    "\n",
    "cartoons = soup.find_all('a', class_='title')\n",
    "for cartoon in cartoons:\n",
    "    print(cartoon.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4. 특정 웹툰정보 가져오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172화\n",
      "https://comic.naver.com/webtoon/detail?titleId=703846&no=177&weekday=tue\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 기본 웹크롤링\n",
    "url = 'https://comic.naver.com/webtoon/list?titleId=703846&weekday=tue'\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "soup = BeautifulSoup(res.text, \"lxml\")\n",
    "\n",
    "cartoons = soup.find_all(\"td\", attrs = {'class':'title'})\n",
    "title = cartoons[0].a.get_text()\n",
    "link = \"https://comic.naver.com\"+cartoons[0].a[\"href\"]\n",
    "\n",
    "print(title)\n",
    "print(link)\n",
    "#cartoons[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172화\n",
      "https://comic.naver.com/webtoon/detail?titleId=703846&no=177&weekday=tue\n",
      "171화\n",
      "https://comic.naver.com/webtoon/detail?titleId=703846&no=176&weekday=tue\n",
      "170화\n",
      "https://comic.naver.com/webtoon/detail?titleId=703846&no=175&weekday=tue\n",
      "169화\n",
      "https://comic.naver.com/webtoon/detail?titleId=703846&no=174&weekday=tue\n",
      "168화\n",
      "https://comic.naver.com/webtoon/detail?titleId=703846&no=173&weekday=tue\n",
      "167화\n",
      "https://comic.naver.com/webtoon/detail?titleId=703846&no=172&weekday=tue\n",
      "166화\n",
      "https://comic.naver.com/webtoon/detail?titleId=703846&no=171&weekday=tue\n",
      "165화\n",
      "https://comic.naver.com/webtoon/detail?titleId=703846&no=170&weekday=tue\n",
      "164화\n",
      "https://comic.naver.com/webtoon/detail?titleId=703846&no=169&weekday=tue\n",
      "163화\n",
      "https://comic.naver.com/webtoon/detail?titleId=703846&no=168&weekday=tue\n"
     ]
    }
   ],
   "source": [
    "cartoons = soup.find_all(\"td\", attrs = {'class':'title'})\n",
    "for cartoon in cartoons :\n",
    "    print(cartoon.a.get_text())\n",
    "    print(\"https://comic.naver.com\"+cartoon.a[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.20 9.20\n",
      "8.17 8.17\n",
      "7.65 7.65\n",
      "6.39 6.39\n",
      "8.17 8.17\n",
      "8.47 8.47\n",
      "8.34 8.34\n",
      "9.45 9.45\n",
      "9.55 9.55\n",
      "8.78 8.78\n",
      "전체별점 : 84.17\n",
      "평균별점 : 8.417\n"
     ]
    }
   ],
   "source": [
    "# 공통적으로 가지는 부모태그나 클래스를 먼저 찾아주기\n",
    "points = soup.find_all('div', attrs={'class':'rating_type'})\n",
    "\n",
    "total_points=0\n",
    "for point in points :\n",
    "    rate1 = point.find(\"strong\").get_text()\n",
    "    rate2 = point.strong.get_text()\n",
    "    print(rate1,rate2)\n",
    "    total_points += float(rate1)\n",
    "    \n",
    "print(\"전체별점 :\",total_points)\n",
    "print(\"평균별점 :\",total_points/len(points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**연습문제2) 네이버 웹툰 중에서 좋아하는 웹툰 정보(회차/링크/별점) 가지고 오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아홉수 우리들 수박양\n",
      "특별편2 https://comic.naver.com//webtoon/detail?titleId=724815&no=122&weekday=sat 9.98\n",
      "120. 일년의 반 https://comic.naver.com//webtoon/detail?titleId=724815&no=121&weekday=sat 9.98\n",
      "119. 모르겠어 https://comic.naver.com//webtoon/detail?titleId=724815&no=120&weekday=sat 9.99\n",
      "118. Don't call me https://comic.naver.com//webtoon/detail?titleId=724815&no=119&weekday=sat 9.98\n",
      "117. 오늘부터 1일♡ https://comic.naver.com//webtoon/detail?titleId=724815&no=118&weekday=sat 9.98\n",
      "116. strawberries & cigarettes https://comic.naver.com//webtoon/detail?titleId=724815&no=117&weekday=sat 9.98\n",
      "115. 산의 연애 https://comic.naver.com//webtoon/detail?titleId=724815&no=116&weekday=sat 9.98\n",
      "114. JUNE https://comic.naver.com//webtoon/detail?titleId=724815&no=115&weekday=sat 9.98\n",
      "113. 아무렇지도 https://comic.naver.com//webtoon/detail?titleId=724815&no=114&weekday=sat 9.98\n",
      "112. 그냥 그렇게 下 https://comic.naver.com//webtoon/detail?titleId=724815&no=113&weekday=sat 9.98\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://comic.naver.com/webtoon/list?titleId=724815&weekday=sat'\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "soup = BeautifulSoup(res.text, \"lxml\")\n",
    "\n",
    "cartoons = soup.find_all(\"td\", attrs={\"class\":\"title\"})\n",
    "points = soup.find_all(\"div\", attrs={\"class\":\"rating_type\"})\n",
    "cartoon_title = soup.find(\"div\", attrs={\"class\":\"detail\"})\n",
    "print(cartoon_title.h2.get_text()[12:19], cartoon_title.span.next_sibling.get_text().strip())\n",
    "\n",
    "for i in range(10):\n",
    "    title = cartoons[i].a.get_text()\n",
    "    link = \"https://comic.naver.com/\"+cartoons[i].a[\"href\"]\n",
    "    point = points[i].strong.get_text()\n",
    "    print(title, link, point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아홉수 우리들 수박양\n",
      "특별편2 https://comic.naver.com/webtoon/detail?titleId=724815&no=122&weekday=sat 9.98\n",
      "120. 일년의 반 https://comic.naver.com/webtoon/detail?titleId=724815&no=121&weekday=sat 9.98\n",
      "119. 모르겠어 https://comic.naver.com/webtoon/detail?titleId=724815&no=120&weekday=sat 9.99\n",
      "118. Don't call me https://comic.naver.com/webtoon/detail?titleId=724815&no=119&weekday=sat 9.98\n",
      "117. 오늘부터 1일♡ https://comic.naver.com/webtoon/detail?titleId=724815&no=118&weekday=sat 9.98\n",
      "116. strawberries & cigarettes https://comic.naver.com/webtoon/detail?titleId=724815&no=117&weekday=sat 9.98\n",
      "115. 산의 연애 https://comic.naver.com/webtoon/detail?titleId=724815&no=116&weekday=sat 9.98\n",
      "114. JUNE https://comic.naver.com/webtoon/detail?titleId=724815&no=115&weekday=sat 9.98\n",
      "113. 아무렇지도 https://comic.naver.com/webtoon/detail?titleId=724815&no=114&weekday=sat 9.98\n",
      "112. 그냥 그렇게 下 https://comic.naver.com/webtoon/detail?titleId=724815&no=113&weekday=sat 9.98\n"
     ]
    }
   ],
   "source": [
    "# 교수님 답\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 기본 웹크롤링\n",
    "url = 'https://comic.naver.com/webtoon/list?titleId=724815&weekday=sat'\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "soup = BeautifulSoup(res.text, \"lxml\")\n",
    "\n",
    "# 제목 구하기\n",
    "title =  soup.find(\"div\", class_=\"detail\")\n",
    "print(title.h2.get_text().strip()[:7], title.h2.span.next_sibling.get_text().strip())\n",
    "\n",
    "# 별점 구하기\n",
    "cartoons = soup.find_all(\"div\", class_=\"rating_type\")\n",
    "point = []\n",
    "for cartoon in cartoons:\n",
    "    point.append(cartoon.find(\"strong\").get_text())\n",
    "    \n",
    "# 회차/링크 구하기\n",
    "cartoons = soup.find_all(\"td\", class_=\"title\")\n",
    "\n",
    "for idx, cartoon in enumerate(cartoons) :\n",
    "    cartoons = soup.find_all(\"td\", class_=\"title\")\n",
    "    title = cartoon.a.get_text()\n",
    "    link = \"https://comic.naver.com\"+cartoon.a[\"href\"]\n",
    "    print(title, link, point[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
